{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fmri_on_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPgKRBbDDrCiBPp4CZZ6pI2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redstoneyard/fmri/blob/master/fmri_on_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMJgYM31y35J"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF0LnUSQ9jIM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "5006238d-abfc-4d59-9d74-a4f46fc83da4"
      },
      "source": [
        "#import os\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#os.chdir(os.path.dirname(os.path.realpath(__file__)))\n",
        "#print(os.getcwd())\n",
        "\n",
        "num_of_features = 5\n",
        "num_of_trees = 200\n",
        "\n",
        "# correlation-current_flow_betweenness-matrix-0.000000\n",
        "# correlation-eigenvector-matrix-0.000000\n",
        "\n",
        "start_time = time.clock()\n",
        "\n",
        "all_data_set = []\n",
        "all_label_set = []\n",
        "\n",
        "graph_file = open('/content/drive/My Drive/data_for_colab/unweighted-correlation-betweenness-matrix-6-0.500000.csv','r')\n",
        "\n",
        "labels_universe = [0, 1, 2]\n",
        "label_pots = {}\n",
        "\n",
        "for line in graph_file:\n",
        "    line = (line.rstrip()).split(',')\n",
        "    patient_label = int(line[0][0]) \n",
        "    patient_data = []\n",
        "    if patient_label not in labels_universe:\n",
        "        pass\n",
        "    else:\n",
        "        for i in range(1,len(line)):\n",
        "            patient_data.append(float(line[i]))\n",
        "        all_data_set.append(patient_data)\n",
        "        all_label_set.append(patient_label)\n",
        "        if patient_label in label_pots.keys():\n",
        "            label_pots[patient_label].append(len(all_data_set) - 1)\n",
        "        else:\n",
        "            label_pots[patient_label] = [len(all_data_set) - 1]\n",
        "\n",
        "    \n",
        "all_data_set = np.array(all_data_set)\n",
        "all_label_set = np.array(all_label_set)\n",
        "\n",
        "\n",
        "all_data_set_reduced = SelectKBest(k = num_of_features).fit_transform(all_data_set, all_label_set)\n",
        "\n",
        "\n",
        "'''\n",
        "sel = VarianceThreshold(threshold = 0.00003)\n",
        "all_data_set_reduced = sel.fit_transform(all_data_set)\n",
        "'''\n",
        "\n",
        "'''\n",
        "all_data_set_reduced = all_data_set \n",
        "'''\n",
        "\n",
        "result_file = open ('result_file.txt','w')\n",
        "\n",
        "label_pots_lists = []\n",
        "label_pots_keys = label_pots.keys()\n",
        "for x in label_pots_keys:\n",
        "    label_pots_lists.append(label_pots[x])\n",
        "\n",
        "prediction_count = {}\n",
        "for x in labels_universe:\n",
        "    prediction_count[x] = {}\n",
        "    for y in labels_universe:\n",
        "        prediction_count[x][y] = 0\n",
        "\n",
        "for k in range(48):\n",
        "    skipped_set = [k]\n",
        "    #print(skipped_set)\n",
        "    training_data_set = []\n",
        "    training_label_set = []\n",
        "    test_data_set = []\n",
        "    test_label_set = []\n",
        "    for patient_ticket in range(0,len(all_data_set_reduced)):\n",
        "        patient_label = all_label_set[patient_ticket]\n",
        "        patient_data = all_data_set_reduced[patient_ticket]\n",
        "        #print(len(patient_data))\n",
        "        if patient_ticket in skipped_set:\n",
        "            test_data_set.append(patient_data)\n",
        "            test_label_set.append(patient_label)\n",
        "        else:\n",
        "            training_data_set.append(patient_data)\n",
        "            training_label_set.append(patient_label)    \n",
        "    clf = RandomForestClassifier(n_estimators = num_of_trees, criterion = 'entropy')\n",
        "    clf.fit(training_data_set, training_label_set)\n",
        "    #print(test_label_set)\n",
        "    prediction = clf.predict(test_data_set)\n",
        "    result_file.write(str(test_label_set)+'\\n'+str(prediction)+'\\n'+'---\\n')\n",
        "    for i in range(0,len(test_label_set)):\n",
        "        prediction_count[test_label_set[i]][prediction[i]] += 1\n",
        "        \n",
        "\n",
        "        \n",
        "print(time.clock()-start_time)\n",
        "\n",
        "print(label_pots)\n",
        "\n",
        "print(label_pots_lists)\n",
        "\n",
        "test_case_label = {}\n",
        "test_case_prediction = {}\n",
        "\n",
        "for i in labels_universe:\n",
        "    test_case_label[i] = 0\n",
        "    for j in labels_universe:\n",
        "        test_case_label[i] += prediction_count[i][j]\n",
        "    test_case_prediction[i] = 0\n",
        "    for j in labels_universe:\n",
        "        test_case_prediction[i] += prediction_count[j][i]\n",
        "\n",
        "for i, j in product(labels_universe, labels_universe):\n",
        "    print(i, j, prediction_count[i][j], float(prediction_count[i][j])/float(test_case_label[i]))\n",
        "    \n",
        "for i, j in product(labels_universe, labels_universe):\n",
        "    print(j, i, prediction_count[j][i], float(prediction_count[j][i])/float(test_case_prediction[i]))\n",
        "    \n",
        "print('--End--')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "12.61950499999999\n",
            "{0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], 1: [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], 2: [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]}\n",
            "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]]\n",
            "0 0 6 0.42857142857142855\n",
            "0 1 6 0.42857142857142855\n",
            "0 2 2 0.14285714285714285\n",
            "1 0 6 0.2608695652173913\n",
            "1 1 16 0.6956521739130435\n",
            "1 2 1 0.043478260869565216\n",
            "2 0 2 0.18181818181818182\n",
            "2 1 3 0.2727272727272727\n",
            "2 2 6 0.5454545454545454\n",
            "0 0 6 0.42857142857142855\n",
            "1 0 6 0.42857142857142855\n",
            "2 0 2 0.14285714285714285\n",
            "0 1 6 0.24\n",
            "1 1 16 0.64\n",
            "2 1 3 0.12\n",
            "0 2 2 0.2222222222222222\n",
            "1 2 1 0.1111111111111111\n",
            "2 2 6 0.6666666666666666\n",
            "--End--\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5UhQAWY7Li5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "9fb4def3-2611-4ea1-89dc-a7d275bb1978"
      },
      "source": [
        "#import os\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "#from sklearn.model_selection import KFold\n",
        "from itertools import product\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "num_of_features = 5\n",
        "num_of_trees = 200\n",
        "\n",
        "\n",
        "start_time = time.clock()\n",
        "\n",
        "all_data_set = []\n",
        "all_label_set = []\n",
        "\n",
        "graph_file = open('/content/drive/My Drive/data_for_colab/unweighted-correlation-betweenness-matrix-6-0.500000.csv','r')\n",
        "\n",
        "labels_universe = [0, 1, 2]\n",
        "label_pots = {}\n",
        "\n",
        "for line in graph_file:\n",
        "    line = (line.rstrip()).split(',')\n",
        "    patient_label = int(line[0][0]) \n",
        "    patient_data = []\n",
        "    if patient_label not in labels_universe:\n",
        "        pass\n",
        "    else:\n",
        "        for i in range(1,len(line)):\n",
        "            patient_data.append(float(line[i]))\n",
        "        all_data_set.append(patient_data)\n",
        "        all_label_set.append(patient_label)\n",
        "        if patient_label in label_pots.keys():\n",
        "            label_pots[patient_label].append(len(all_data_set) - 1)\n",
        "        else:\n",
        "            label_pots[patient_label] = [len(all_data_set) - 1]\n",
        "\n",
        "    \n",
        "all_data_set = np.array(all_data_set)\n",
        "all_label_set = np.array(all_label_set)\n",
        "\n",
        "\n",
        "all_data_set_reduced = SelectKBest(k = num_of_features).fit_transform(all_data_set, all_label_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "result_file = open ('result_file.txt','w')\n",
        "\n",
        "label_pots_lists = []\n",
        "label_pots_keys = label_pots.keys()\n",
        "for x in label_pots_keys:\n",
        "    label_pots_lists.append(label_pots[x])\n",
        "\n",
        "prediction_count = {}\n",
        "for x in labels_universe:\n",
        "    prediction_count[x] = {}\n",
        "    for y in labels_universe:\n",
        "        prediction_count[x][y] = 0\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "# kf = KFold(n_splits = 5)\n",
        "\n",
        "\n",
        "for train_index, test_index in loo.split(all_data_set_reduced): # or kf.split(all_data_set_reduced)\n",
        "    training_data_set, test_data_set = all_data_set_reduced[train_index], all_data_set_reduced[test_index]\n",
        "    training_label_set, test_label_set = all_label_set[train_index], all_label_set[test_index]\n",
        "    clf = RandomForestClassifier(n_estimators = num_of_trees, criterion = 'entropy')\n",
        "    clf.fit(training_data_set, training_label_set)\n",
        "    #print(test_label_set)\n",
        "    prediction = clf.predict(test_data_set)\n",
        "    result_file.write(str(test_label_set)+'\\n'+str(prediction)+'\\n'+'---\\n')\n",
        "    for i in range(0,len(test_label_set)):\n",
        "        prediction_count[test_label_set[i]][prediction[i]] += 1\n",
        "        \n",
        "print(time.clock()-start_time)\n",
        "\n",
        "print(label_pots)\n",
        "\n",
        "print(label_pots_lists)\n",
        "\n",
        "test_case_label = {}\n",
        "test_case_prediction = {}\n",
        "\n",
        "for i in labels_universe:\n",
        "    test_case_label[i] = 0\n",
        "    for j in labels_universe:\n",
        "        test_case_label[i] += prediction_count[i][j]\n",
        "    test_case_prediction[i] = 0\n",
        "    for j in labels_universe:\n",
        "        test_case_prediction[i] += prediction_count[j][i]\n",
        "\n",
        "for i, j in product(labels_universe, labels_universe):\n",
        "    print(i, j, prediction_count[i][j], float(prediction_count[i][j])/float(test_case_label[i]))\n",
        "    \n",
        "for i, j in product(labels_universe, labels_universe):\n",
        "    print(j, i, prediction_count[j][i], float(prediction_count[j][i])/float(test_case_prediction[i]))\n",
        "    \n",
        "print('--End--')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "13.349397999999999\n",
            "{0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], 1: [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], 2: [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]}\n",
            "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]]\n",
            "0 0 6 0.42857142857142855\n",
            "0 1 6 0.42857142857142855\n",
            "0 2 2 0.14285714285714285\n",
            "1 0 5 0.21739130434782608\n",
            "1 1 17 0.7391304347826086\n",
            "1 2 1 0.043478260869565216\n",
            "2 0 2 0.18181818181818182\n",
            "2 1 3 0.2727272727272727\n",
            "2 2 6 0.5454545454545454\n",
            "0 0 6 0.46153846153846156\n",
            "1 0 5 0.38461538461538464\n",
            "2 0 2 0.15384615384615385\n",
            "0 1 6 0.23076923076923078\n",
            "1 1 17 0.6538461538461539\n",
            "2 1 3 0.11538461538461539\n",
            "0 2 2 0.2222222222222222\n",
            "1 2 1 0.1111111111111111\n",
            "2 2 6 0.6666666666666666\n",
            "--End--\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6hBWLtFIMF0"
      },
      "source": [
        ""
      ]
    }
  ]
}